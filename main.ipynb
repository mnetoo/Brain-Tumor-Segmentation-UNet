{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fffe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMG_SIZE = 256 \n",
    "EPOCHS = 15\n",
    "dataset_path = './kaggle_3m/kaggle_3m' \n",
    "\n",
    "# Busca arquivos\n",
    "mask_files = glob.glob(os.path.join(dataset_path, '*/*_mask*'))\n",
    "train_files = [m.replace('_mask', '') for m in mask_files]\n",
    "\n",
    "if len(train_files) == 0:\n",
    "    print(\"ERRO: Nenhuma imagem encontrada.\")\n",
    "\n",
    "df = pd.DataFrame({\"image_path\": train_files, \"mask_path\": mask_files})\n",
    "train_df, val_df = train_test_split(df, test_size=0.15)\n",
    "\n",
    "# Dataset TensorFlow\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def read_and_process_image(image_path, mask_path):\n",
    "    img_p = image_path.decode('utf-8')\n",
    "    msk_p = mask_path.decode('utf-8')\n",
    "    \n",
    "    img = cv2.imread(img_p) \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    \n",
    "    mask = cv2.imread(msk_p, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "    mask = mask / 255.0\n",
    "    mask = (mask > 0.5).astype(np.float32)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    return img.astype(np.float32), mask.astype(np.float32)\n",
    "\n",
    "def tf_process_wrapper(image_path, mask_path):\n",
    "    img, mask = tf.numpy_function(read_and_process_image, [image_path, mask_path], [tf.float32, tf.float32])\n",
    "    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "    mask.set_shape([IMG_SIZE, IMG_SIZE, 1])\n",
    "    return img, mask\n",
    "\n",
    "def create_dataset_safe(dataframe):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dataframe['image_path'].values, dataframe['mask_path'].values))\n",
    "    ds = ds.map(tf_process_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(32)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = create_dataset_safe(train_df)\n",
    "val_ds = create_dataset_safe(val_df)\n",
    "\n",
    "# Modelo U-Net\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_model(input_size=(IMG_SIZE, IMG_SIZE, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(b)\n",
    "    u1 = layers.concatenate([u1, c3])\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
    "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u2 = layers.concatenate([u2, c2])\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
    "    u3 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u3 = layers.concatenate([u3, c1])\n",
    "    c6 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u3)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c6)\n",
    "    return models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "# Métrica Dice\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "\n",
    "print(\"Iniciando Treinamento...\")\n",
    "# Dica: reduza epochs se seu PC for lento\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS) \n",
    "print(\"Treinamento Concluído.\")\n",
    "\n",
    "# Visualização\n",
    "def plot_better_prediction(model, dataset):\n",
    "    for image, mask in dataset.take(1):\n",
    "        pred_raw = model.predict(image)\n",
    "        pred_clean = (pred_raw > 0.5).astype(np.float32)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image[0])\n",
    "        plt.title(\"Imagem\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask[0], cmap='gray')\n",
    "        plt.title(\"Real\")\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_clean[0], cmap='gray')\n",
    "        plt.title(\"Rede\")\n",
    "        plt.show()\n",
    "\n",
    "plot_better_prediction(model, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1983ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva toda a inteligência da rede neural num arquivo físico\n",
    "model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tumor_mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
